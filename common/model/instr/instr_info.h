#pragma once

#include <algorithm>
#include <cassert>
#include <cstring>
#include <unordered_map>

enum InstrKey {

    // SMEM
    S_ATOMIC_ADD,
    S_ATOMIC_ADD_X2,
    S_ATOMIC_AND,
    S_ATOMIC_AND_X2,
    S_ATOMIC_CMPSWAP,
    S_ATOMIC_CMPSWAP_X2,
    S_ATOMIC_DEC,
    S_ATOMIC_DEC_X2,
    S_ATOMIC_INC,
    S_ATOMIC_INC_X2,
    S_ATOMIC_OR,
    S_ATOMIC_OR_X2,
    S_ATOMIC_SMAX,
    S_ATOMIC_SMAX_X2,
    S_ATOMIC_SMIN,
    S_ATOMIC_SMIN_X2,
    S_ATOMIC_SUB,
    S_ATOMIC_SUB_X2,
    S_ATOMIC_SWAP,
    S_ATOMIC_SWAP_X2,
    S_ATOMIC_UMAX,
    S_ATOMIC_UMAX_X2,
    S_ATOMIC_UMIN,
    S_ATOMIC_UMIN_X2,
    S_ATOMIC_XOR,
    S_ATOMIC_XOR_X2,
    S_BUFFER_ATOMIC_ADD,
    S_BUFFER_ATOMIC_ADD_X2,
    S_BUFFER_ATOMIC_AND,
    S_BUFFER_ATOMIC_AND_X2,
    S_BUFFER_ATOMIC_CMPSWAP,
    S_BUFFER_ATOMIC_CMPSWAP_X2,
    S_BUFFER_ATOMIC_DEC,
    S_BUFFER_ATOMIC_DEC_X2,
    S_BUFFER_ATOMIC_INC,
    S_BUFFER_ATOMIC_INC_X2,
    S_BUFFER_ATOMIC_OR,
    S_BUFFER_ATOMIC_OR_X2,
    S_BUFFER_ATOMIC_SMAX,
    S_BUFFER_ATOMIC_SMAX_X2,
    S_BUFFER_ATOMIC_SMIN,
    S_BUFFER_ATOMIC_SMIN_X2,
    S_BUFFER_ATOMIC_SUB,
    S_BUFFER_ATOMIC_SUB_X2,
    S_BUFFER_ATOMIC_SWAP,
    S_BUFFER_ATOMIC_SWAP_X2,
    S_BUFFER_ATOMIC_UMAX,
    S_BUFFER_ATOMIC_UMAX_X2,
    S_BUFFER_ATOMIC_UMIN,
    S_BUFFER_ATOMIC_UMIN_X2,
    S_BUFFER_ATOMIC_XOR,
    S_BUFFER_ATOMIC_XOR_X2,
    S_BUFFER_LOAD_DWORD,
    S_BUFFER_LOAD_DWORDX16,
    S_BUFFER_LOAD_DWORDX2,
    S_BUFFER_LOAD_DWORDX4,
    S_BUFFER_LOAD_DWORDX8,
    S_BUFFER_STORE_DWORD,
    S_BUFFER_STORE_DWORDX2,
    S_BUFFER_STORE_DWORDX4,
    S_DCACHE_DISCARD,
    S_DCACHE_DISCARD_X2,
    S_DCACHE_INV,
    S_DCACHE_INV_VOL,
    S_LOAD_DWORD,
    S_LOAD_DWORDX16,
    S_LOAD_DWORDX2,
    S_LOAD_DWORDX4,
    S_LOAD_DWORDX8,
    S_MEMREALTIME,
    S_MEMTIME,
    S_SCRATCH_LOAD_DWORD,
    S_SCRATCH_LOAD_DWORDX2,
    S_SCRATCH_LOAD_DWORDX4,
    S_SCRATCH_STORE_DWORD,
    S_SCRATCH_STORE_DWORDX2,
    S_SCRATCH_STORE_DWORDX4,
    S_STORE_DWORD,
    S_STORE_DWORDX2,
    S_STORE_DWORDX4,

    // SOPC
    S_BITCMP0_B32,
    S_BITCMP0_B64,
    S_BITCMP1_B32,
    S_BITCMP1_B64,
    S_CMP_EQ_I32,
    S_CMP_EQ_U32,
    S_CMP_EQ_U64,
    S_CMP_GE_I32,
    S_CMP_GE_U32,
    S_CMP_GT_I32,
    S_CMP_GT_U32,
    S_CMP_LE_I32,
    S_CMP_LE_U32,
    S_CMP_LG_I32,
    S_CMP_LG_U32,
    S_CMP_LG_U64,
    S_CMP_NE_U64,
    S_CMP_LT_I32,
    S_CMP_LT_U32,
    S_SET_GPR_IDX_ON,
    S_SETVSKIP,
    // END SOPC

    // SOPP
    S_BARRIER,
    S_BRANCH,
    S_CBRANCH_CDBGSYS,
    S_CBRANCH_CDBGSYS_AND_USER,
    S_CBRANCH_CDBGSYS_OR_USER,
    S_CBRANCH_CDBGUSER,
    S_CBRANCH_EXECNZ,
    S_CBRANCH_EXECZ,
    S_CBRANCH_SCC0,
    S_CBRANCH_SCC1,
    S_CBRANCH_VCCNZ,
    S_CBRANCH_VCCZ,
    S_DECPERFLEVEL,
    S_ENDPGM,
    S_ENDPGM_ORDERED_PS_DONE,
    S_ENDPGM_SAVED,
    S_ICACHE_INV,
    S_INCPERFLEVEL,
    S_NOP,
    S_SENDMSG,
    S_SENDMSGHALT,
    S_SET_GPR_IDX_MODE,
    S_SET_GPR_IDX_OFF,
    S_SETHALT,
    S_SETKILL,
    S_SETPRIO,
    S_SLEEP,
    S_TRAP,
    S_TTRACEDATA,
    S_WAITCNT,
    // END SOPP

    // SOP1_FORMAT
    S_ABS_I32,
    S_AND_SAVEEXEC_B64,
    S_ANDN1_SAVEEXEC_B64,
    S_ANDN1_WREXEC_B64,
    S_ANDN2_SAVEEXEC_B64,
    S_ANDN2_WREXEC_B64,
    S_BCNT0_I32_B32,
    S_BCNT0_I32_B64,
    S_BCNT1_I32_B32,
    S_BCNT1_I32_B64,
    S_BITREPLICATE_B64_B32,
    S_BITSET0_B32,
    S_BITSET0_B64,
    S_BITSET1_B32,
    S_BITSET1_B64,
    S_BREV_B32,
    S_BREV_B64,
    S_CBRANCH_JOIN,
    S_CMOV_B32,
    S_CMOV_B64,
    S_FF0_I32_B32,
    S_FF0_I32_B64,
    S_FF1_I32_B32,
    S_FF1_I32_B64,
    S_FLBIT_I32_B32,
    S_FLBIT_I32_B64,
    S_FLBIT_I32,
    S_FLBIT_I32_I64,
    S_GETPC_B64,
    S_MOV_B32,
    S_MOV_B64,
    S_MOVRELD_B32,
    S_MOVRELD_B64,
    S_MOVRELS_B32,
    S_MOVRELS_B64,
    S_NAND_SAVEEXEC_B64,
    S_NOR_SAVEEXEC_B64,
    S_NOT_B32,
    S_NOT_B64,
    S_OR_SAVEEXEC_B64,
    S_ORN2_SAVEEXEC_B64,
    S_QUADMASK_B32,
    S_QUADMASK_B64,
    S_RFE_B64,
    S_SET_GPR_IDX_IDX,
    S_SETPC_B64,
    S_SEXT_I32_I8,
    S_SEXT_I32_I16,
    S_SWAPPC_B64,
    S_WQM_B32,
    S_WQM_B64,
    S_XNOR_SAVEEXEC_B64,
    S_XOR_SAVEEXEC_B64,
    // END SOP1_FORMAT

    // SOP2_FORMAT
    S_ABSDIFF_I32,
    S_ADDC_U32,
    S_ADD_I32,
    S_ADD_U32,
    S_AND_B32,
    S_AND_B64,
    S_ANDN2_B32,
    S_ANDN2_B64,
    S_ASHR_I32,
    S_ASHR_I64,
    S_BFE_I32,
    S_BFE_I64,
    S_BFE_U32,
    S_BFE_U64,
    S_BFM_B32,
    S_BFM_B64,
    S_CBRANCH_G_FORK,
    S_CSELECT_B32,
    S_CSELECT_B64,
    S_LSHL_B32,
    S_LSHL_B64,
    S_LSHL1_ADD_U32,
    S_LSHL2_ADD_U32,
    S_LSHL3_ADD_U32,
    S_LSHL4_ADD_U32,
    S_LSHR_B32,
    S_LSHR_B64,
    S_MAX_I32,
    S_MAX_U32,
    S_MIN_I32,
    S_MIN_U32,
    S_MUL_HI_I32,
    S_MUL_HI_U32,
    S_MUL_I32,
    S_NAND_B32,
    S_NAND_B64,
    S_NOR_B32,
    S_NOR_B64,
    S_OR_B32,
    S_OR_B64,
    S_ORN2_B32,
    S_ORN2_B64,
    S_PACK_HH_B32_B16,
    S_PACK_LH_B32_B16,
    S_PACK_LL_B32_B16,
    S_RFE_RESTORE_B64,
    S_SUBB_U32,
    S_SUB_I32,
    S_SUB_U32,
    S_XNOR_B32,
    S_XNOR_B64,
    S_XOR_B32,
    S_XOR_B64,
    // END SOP2_FORMAT

    // SOPK_FORMAT
    S_ADDK_I32,
    S_CALL_B64,
    S_CBRANCH_I_FORK,
    S_CMOVK_I32,
    S_CMPK_EQ_I32,
    S_CMPK_EQ_U32,
    S_CMPK_GE_I32,
    S_CMPK_GE_U32,
    S_CMPK_GT_I32,
    S_CMPK_GT_U32,
    S_CMPK_LE_I32,
    S_CMPK_LE_U32,
    S_CMPK_LG_I32,
    S_CMPK_LG_U32,
    S_CMPK_LT_I32,
    S_CMPK_LT_U32,
    S_GETREG_B32,
    S_MOVK_I32,
    S_MULK_I32,
    S_SETREG_B32,
    S_SETREG_IMM32_B32,
    // END SOPK_FORMAT

    // VOP1
    V_BFREV_B32,
    V_FFBH_U32,
    V_FFBH_I32,
    V_FFBL_B32,
    V_MOV_B32,
    V_SWAP_B32,
    V_MOVRELD_B32,
    V_MOVRELS_B32,
    V_MOVRELSD_B32,
    V_NOT_B32,
    V_READFIRSTLANE_B32,
    V_SAT_PK_U8_I16,
    V_SCREEN_PARTITION_4SE_B32,
    V_NOP,
    V_CVT_I32_F64,
    V_CVT_F64_I32,
    V_CVT_F32_I32,
    V_CVT_F32_U32,
    V_CVT_U32_F32,
    V_CVT_I32_F32,
    V_CVT_F16_F32,
    V_CVT_F32_F16,
    V_CVT_RPI_I32_F32,
    V_CVT_FLR_I32_F32,
    V_CVT_OFF_F32_I4,
    V_CVT_F32_F64,
    V_CVT_F64_F32,
    V_CVT_F32_UBYTE0,
    V_CVT_F32_UBYTE1,
    V_CVT_F32_UBYTE2,
    V_CVT_F32_UBYTE3,
    V_CVT_U32_F64,
    V_CVT_F64_U32,
    V_TRUNC_F64,
    V_CEIL_F64,
    V_RNDNE_F64,
    V_FLOOR_F64,
    V_FRACT_F32,
    V_TRUNC_F32,
    V_CEIL_F32,
    V_RNDNE_F32,
    V_FLOOR_F32,
    V_EXP_F32,
    V_LOG_F32,
    V_RCP_F32,
    V_RCP_IFLAG_F32,
    V_RSQ_F32,
    V_RCP_F64,
    V_RSQ_F64,
    V_SQRT_F32,
    V_SQRT_F64,
    V_SIN_F32,
    V_COS_F32,
    V_FREXP_EXP_I32_F64,
    V_FREXP_MANT_F64,
    V_FRACT_F64,
    V_FREXP_EXP_I32_F32,
    V_FREXP_MANT_F32,
    V_CLREXCP,
    V_CVT_F16_U16,
    V_CVT_F16_I16,
    V_CVT_U16_F16,
    V_CVT_I16_F16,
    V_RCP_F16,
    V_SQRT_F16,
    V_RSQ_F16,
    V_LOG_F16,
    V_EXP_F16,
    V_FREXP_MANT_F16,
    V_FREXP_EXP_I16_F16,
    V_FLOOR_F16,
    V_CEIL_F16,
    V_TRUNC_F16,
    V_RNDNE_F16,
    V_FRACT_F16,
    V_SIN_F16,
    V_COS_F16,
    V_EXP_LEGACY_F32,
    V_LOG_LEGACY_F32,
    V_CVT_NORM_I16_F16,
    V_CVT_NORM_U16_F16,

    // VOP2
    V_ADD_U32,
    V_ASHR_I32,
    V_ASHRREV_B16,
    V_LSHR_B32,
    V_SUB_U32,
    V_ADDC_U32,
    V_CNDMASK_B32,
    V_ADD_F32,
    V_SUB_F32,
    V_SUBREV_F32,
    V_MUL_LEGACY_F32,
    V_MUL_F32,
    V_MUL_I32_I24,
    V_MUL_HI_I32_I24,
    V_MUL_U32_U24,
    V_MUL_HI_U32_U24,
    V_MIN_F32,
    V_MAX_F32,
    V_MIN_I32,
    V_MAX_I32,
    V_MIN_U32,
    V_MAX_U32,
    V_LSHRREV_B32,
    V_ASHRREV_I32,
    V_LSHLREV_B32,
    V_AND_B32,
    V_OR_B32,
    V_XOR_B32,
    V_MAC_F32,
    V_MADMK_F32,
    V_MADAK_F32,
    V_ADD_CO_U32,
    V_SUB_CO_U32,
    V_SUBREV_CO_U32,
    V_ADDC_CO_U32,
    V_SUBB_CO_U32,
    V_SUBBREV_CO_U32,
    V_ADD_F16,
    V_SUB_F16,
    V_SUBREV_F16,
    V_MUL_F16,
    V_MAC_F16,
    V_MADMK_F16,
    V_MADAK_F16,
    V_ADD_U16,
    V_SUB_U16,
    V_SUBREV_U16,
    V_MUL_LO_U16,
    V_LSHLREV_B16,
    V_LSHRREV_B16,
    V_ASHRREV_I16,
    V_MAX_F16,
    V_MIN_F16,
    V_MAX_U16,
    V_MAX_I16,
    V_MIN_U16,
    V_MIN_I16,
    V_LDEXP_F16,
    V_SUBREV_U32,

    // VOP3
    V_MUL_LO_U32,
    V_ADD3_U32,
    V_ADD_LSHL_U32,
    V_AND_OR_B32,
    V_ASHR_I64,
    V_BCNT_U32_B32,
    V_LSHL_ADD_U32,
    V_LSHL_B64,
    V_LSHL_OR_B32,
    V_LSHR_B64,
    V_LSHRREV_B64,
    V_MAD_I16,
    V_MAD_I32_I16,
    V_MAD_U16,
    V_MAD_U32_U16,
    V_MAX3_I16,
    V_MAX3_U16,
    V_MBCNT_HI_U32_B32,
    V_MBCNT_LO_U32_B32,
    V_MED3_I16,
    V_MED3_U16,
    V_MIN3_I16,
    V_MIN3_U16,
    V_MUL_HI_I32,
    V_MUL_HI_U32,
    V_MUL_LO_I32,
    V_OR3_B32,
    V_READLANE_B32,
    V_WRITELANE_B32,
    V_XAD_U32,

    // VOP3A
    V_LSHLREV_B64,
    V_MAD_LEGACY_F32,
    V_MAD_F32,
    V_MAD_I32_I24,
    V_MAD_U32_U24,
    V_CUBEID_F32,
    V_CUBESC_F32,
    V_CUBETC_F32,
    V_CUBEMA_F32,
    V_BFE_U32,
    V_BFE_I32,
    V_BFI_B32,
    V_FMA_F32,
    V_FMA_F64,
    V_LERP_U8,
    V_ALIGNBIT_B32,
    V_ALIGNBYTE_B32,
    V_MIN3_F32,
    V_MIN3_I32,
    V_MIN3_U32,
    V_MAX3_F32,
    V_MAX3_I32,
    V_MAX3_U32,
    V_MED3_F32,
    V_MED3_I32,
    V_MED3_U32,
    V_SAD_U8,
    V_SAD_HI_U8,
    V_SAD_U16,
    V_SAD_U32,
    V_CVT_PK_U8_F32,
    V_DIV_FIXUP_F32,
    V_DIV_FIXUP_F64,
    V_DIV_FMAS_F32,
    V_DIV_FMAS_F64,
    V_MSAD_U8,
    V_QSAD_PK_U16_U8,
    V_MQSAD_PK_U16_U8,
    V_MQSAD_U32_U8,
    V_MAD_LEGACY_F16,
    V_MAD_LEGACY_U16,
    V_MAD_LEGACY_I16,
    V_PERM_B32,
    V_FMA_LEGACY_F16,
    V_DIV_FIXUP_LEGACY_F16,
    V_CVT_PKACCUM_U8_F32,
    V_ASHRREV_I64,
    V_TRIG_PREOP_F64,
    V_BFM_B32,
    V_CVT_PKNORM_I16_F32,
    V_CVT_PKNORM_U16_F32,
    V_CVT_PKRTZ_F16_F32,
    V_CVT_PK_U16_U32,
    V_CVT_PK_I16_I32,
    V_CVT_PKNORM_I16_F16,
    V_CVT_PKNORM_U16_F16,
    V_ADD_I32,
    V_SUB_I32,
    V_ADD_I16,
    V_SUB_I16,
    V_PACK_B32_F16,

    // VOP3B
    V_DIV_SCALE_F32,
    V_DIV_SCALE_F64,
    V_MAD_U64_U32,
    V_MAD_I64_I32,

    // VOPC
    V_CMP_F_I16,
    V_CMP_LT_I16,
    V_CMP_EQ_I16,
    V_CMP_LE_I16,
    V_CMP_GT_I16,
    V_CMP_LG_I16,
    V_CMP_GE_I16,
    V_CMP_TRU_I16,
    V_CMP_F_U16,
    V_CMP_LT_U16,
    V_CMP_EQ_U16,
    V_CMP_LE_U16,
    V_CMP_GT_U16,
    V_CMP_LG_U16,
    V_CMP_GE_U16,
    V_CMP_TRU_U16,
    V_CMPX_F_I16,
    V_CMPX_LT_I16,
    V_CMPX_EQ_I16,
    V_CMPX_LE_I16,
    V_CMPX_GT_I16,
    V_CMPX_LG_I16,
    V_CMPX_GE_I16,
    V_CMPX_TRU_I16,
    V_CMPX_F_U16,
    V_CMPX_LT_U16,
    V_CMPX_EQ_U16,
    V_CMPX_LE_U16,
    V_CMPX_GT_U16,
    V_CMPX_LG_U16,
    V_CMPX_GE_U16,
    V_CMPX_TRU_U16,
    V_CMP_F_I32,
    V_CMP_LT_I32,
    V_CMP_EQ_I32,
    V_CMP_LE_I32,
    V_CMP_GT_I32,
    V_CMP_LG_I32,
    V_CMP_GE_I32,
    V_CMP_TRU_I32,
    V_CMP_F_U32,
    V_CMP_LT_U32,
    V_CMP_EQ_U32,
    V_CMP_LE_U32,
    V_CMP_GT_U32,
    V_CMP_LG_U32,
    V_CMP_GE_U32,
    V_CMP_TRU_U32,
    V_CMPX_F_I32,
    V_CMPX_LT_I32,
    V_CMPX_EQ_I32,
    V_CMPX_LE_I32,
    V_CMPX_GT_I32,
    V_CMPX_LG_I32,
    V_CMPX_GE_I32,
    V_CMPX_TRU_I32,
    V_CMPX_F_U32,
    V_CMPX_LT_U32,
    V_CMPX_EQ_U32,
    V_CMPX_LE_U32,
    V_CMPX_GT_U32,
    V_CMPX_LG_U32,
    V_CMPX_GE_U32,
    V_CMPX_TRU_U32,
    V_CMP_F_I64,
    V_CMP_LT_I64,
    V_CMP_EQ_I64,
    V_CMP_LE_I64,
    V_CMP_GT_I64,
    V_CMP_LG_I64,
    V_CMP_GE_I64,
    V_CMP_TRU_I64,
    V_CMP_F_U64,
    V_CMP_LT_U64,
    V_CMP_EQ_U64,
    V_CMP_LE_U64,
    V_CMP_GT_U64,
    V_CMP_LG_U64,
    V_CMP_GE_U64,
    V_CMP_TRU_U64,
    V_CMPX_F_I64,
    V_CMPX_LT_I64,
    V_CMPX_EQ_I64,
    V_CMPX_LE_I64,
    V_CMPX_GT_I64,
    V_CMPX_LG_I64,
    V_CMPX_GE_I64,
    V_CMPX_TRU_I64,
    V_CMPX_F_U64,
    V_CMPX_LT_U64,
    V_CMPX_EQ_U64,
    V_CMPX_LE_U64,
    V_CMPX_GT_U64,
    V_CMPX_LG_U64,
    V_CMPX_GE_U64,
    V_CMPX_TRU_U64,
    V_CMP_F_F32,
    V_CMP_LT_F32,
    V_CMP_EQ_F32,
    V_CMP_LE_F32,
    V_CMP_GT_F32,
    V_CMP_LG_F32,
    V_CMP_GE_F32,
    V_CMP_O_F32,
    V_CMP_U_F32,
    V_CMP_NGE_F32,
    V_CMP_NLG_F32,
    V_CMP_NGT_F32,
    V_CMP_NLE_F32,
    V_CMP_NEQ_F32,
    V_CMP_NLT_F32,
    V_CMP_TRU_F32,
    V_CMPX_F_F32,
    V_CMPX_LT_F32,
    V_CMPX_EQ_F32,
    V_CMPX_LE_F32,
    V_CMPX_GT_F32,
    V_CMPX_LG_F32,
    V_CMPX_GE_F32,
    V_CMPX_O_F32,
    V_CMPX_U_F32,
    V_CMPX_NGE_F32,
    V_CMPX_NLG_F32,
    V_CMPX_NGT_F32,
    V_CMPX_NLE_F32,
    V_CMPX_NEQ_F32,
    V_CMPX_NLT_F32,
    V_CMPX_TRU_F32,
    V_CMPS_F_F64,
    V_CMPS_LT_F64,
    V_CMPS_EQ_F64,
    V_CMPS_LE_F64,
    V_CMPS_GT_F64,
    V_CMPS_LG_F64,
    V_CMPS_GE_F64,
    V_CMPS_O_F64,
    V_CMPS_U_F64,
    V_CMPS_NGE_F64,
    V_CMPS_NLG_F64,
    V_CMPS_NGT_F64,
    V_CMPS_NLE_F64,
    V_CMPS_NEQ_F64,
    V_CMPS_NLT_F64,
    V_CMPS_TRU_F64,
    V_CMPX_F_F64,
    V_CMPX_LT_F64,
    V_CMPX_EQ_F64,
    V_CMPX_LE_F64,
    V_CMPX_GT_F64,
    V_CMPX_LG_F64,
    V_CMPX_GE_F64,
    V_CMPX_O_F64,
    V_CMPX_U_F64,
    V_CMPX_NGE_F64,
    V_CMPX_NLG_F64,
    V_CMPX_NGT_F64,
    V_CMPX_NLE_F64,
    V_CMPX_NEQ_F64,
    V_CMPX_NLT_F64,
    V_CMPX_TRU_F64,

    // FLAT
    FLAT_STORE_DWORD,
    FLAT_STORE_DWORDX2,
    FLAT_STORE_DWORDX3,
    FLAT_STORE_DWORDX4,
    FLAT_STORE_SHORT,
    FLAT_LOAD_DWORD,
    FLAT_LOAD_DWORDX2,
    FLAT_LOAD_DWORDX3,
    FLAT_LOAD_DWORDX4,
    FLAT_ATOMIC_ADD,
    FLAT_ATOMIC_SUB,
    FLAT_ATOMIC_SMIN,
    FLAT_ATOMIC_UMIN,
    FLAT_ATOMIC_SMAX,
    FLAT_ATOMIC_UMAX,
    FLAT_ATOMIC_AND,
    FLAT_ATOMIC_OR,
    FLAT_ATOMIC_XOR,
    FLAT_ATOMIC_INC,
    FLAT_ATOMIC_DEC,
    FLAT_ATOMIC_ADD_X2,
    FLAT_ATOMIC_SUB_X2,
    FLAT_ATOMIC_SMIN_X2,
    FLAT_ATOMIC_UMIN_X2,
    FLAT_ATOMIC_SMAX_X2,
    FLAT_ATOMIC_UMAX_X2,
    FLAT_ATOMIC_AND_X2,
    FLAT_ATOMIC_OR_X2,
    FLAT_ATOMIC_XOR_X2,
    FLAT_ATOMIC_INC_X2,
    FLAT_ATOMIC_DEC_X2
};

enum InstrFormat {
    SOP1,
    SOP2,
    SOPK,
    SOPP,
    SMEM,
    SOPC,
    VOP1,
    VOP2,
    VOPC,
    VINTRP,
    VOP3A,
    VOP3B,
    VOP3P,
    FLAT,
    UNDEFINED
};

InstrKey get_instr_key(const std::string&);

char const* get_mnemonic(InstrKey);

InstrFormat get_instr_format(InstrKey, size_t);
